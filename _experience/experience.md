---
# title: "Paper Title Number 3"
collection: experience
permalink: /experience/experience
# excerpt: "" 
# date: 2015-10-01
# venue: 'Journal 1'
# paperurl: 'http://academicpages.github.io/files/paper3.pdf'
# citation: 'Your Name, You. (2015). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
---


**Work Experience**
---------------------

* 07/2022 - 09/2022: Engineering Intern
  * **Syntiant Corp.**
  * Developed a confidence-aware, multi-teacher knowledge distillation framework for keyword spotting, leveraging the student-teacher architecture. Used pre-trained keyword transformer models to enhance student model accuracy effectively.
  * Location: Irvine, California
  
* 06/2020 - 01/2021: Data Science Internship
  * **Ericsson Inc.**
  * Built a secure federated XGBoost framework with an innovative secure quantile sketch and practical secure aggregation. Implemented pairwise masking of model parameters to protect against gradient leakage attacks during aggregation, strengthening client data privacy.
  * Location: Santa Clara, California

* Winter and Spring 2024, Winter 2025: Teaching Assistant
  * **UCIrvine EECS Department.**
  * Taught the lab sessions of EECS 31L: Introduction to Digital Logic Lab, guiding students through Verilog module design and debugging.
  * Location: Irvine, California

**Research Experience**
---------------------

* **Heterogeneity-Aware Shapley Valuation for Client Selection in FL**, 2023.10 – 2024.9.
  * Developed a heterogeneity-aware Shapley valuation scheme to evaluate the contributions of clients with heterogeneous data in federated learning.
  * Utilized Shapley scores to identify and prioritize the most impactful clients during federated learning training, focusing on those with critical yet underrepresented data to improve model performance and address the challenge of data heterogeneity in FL.


* **PriPrune: Quantifying and Preserving Privacy in Pruned FL**, 2022.11 - 2023.8
  * Conducted research on privacy guarantees for model pruning in FL, deriving information-theoretic upper bounds on information leakage in pruned FL models.
  * Developed PriPrune – a privacy-aware model pruning algorithm featuring personalized, per-client defense masks and adaptive pruning rates, balancing both privacy and model performance effectively.

* **Information Leakage In Personalized Federated Learning**, 2022.4 - 2022.6
  * Executed the gradient leakage attack (DLG attack) in personalized FL, demonstrating how varying personalization levels impact vulnerability to DLG attacks.
  * Proposed PerFed-LDP, a per-example level differential privacy method for personalized FL, analyzing its privacy-utility tradeoff and quantifying DLG attack performance under differentially private settings.

* **Privacy by Projection: Federated Population Density Estimation by Projecting on Random Features**, 2021.12 – 2022.07.
  * Designed a federated kernel density estimation (KDE) framework to estimate population density while ensuring user data remains local.
  * Developed a federated Random Fourier Feature (RFF) KDE approach that leverages a random feature representation, irreversibly projecting user information onto spatially delocalized basis functions, thus enhancing privacy without compromising estimation accuracy.

* **Location Leakage in Federated Signal Maps**, 2021.11 – 2022.04.
  * Executed the gradient leakage (DLG) attack on federated signal map prediction tasks, successfully reconstructing the average location from users' private spatio-temporal datasets during federated training.
  * Proposed a defense strategy that strategically selects local batches to obfuscate the true average location, misleading DLG attacks. Conducted an analysis on the tradeoff between utility in federated signal mapping and privacy protection for clients' location data.

* **SaferQ: Obfuscating Search Queries via Generative Adversarial Privacy**, 2020.03 – 2020.05.
  * Developed SaferQ, an extension of the Generative Adversarial Privacy (GAP) framework for sequence generation, designed to obfuscate search queries while balancing privacy and utility. Deployed between browsers and query log databases, SaferQ anonymizes query logs according to specified privacy-utility trade-off criteria.

* **Secure Federated XGBoost Framework**, 2018.09 – 2019.08.
  * Designed a secure federated XGBoost framework that incorporates anonymized data aggregation to balance privacy and model performance.
