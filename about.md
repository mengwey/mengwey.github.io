---
permalink: /
title: "Mengwei Yang's Academic Homepage"
excerpt: "About me"
author_profile: true
collection: aboutme
redirect_from: 
  - /about/
  - /about.html
---


Biography
======
I am a fourth-year PhD student in the [Electrical Engineering program](https://engineering.uci.edu/dept/eecs) at the University of California, Irvine, advised by Prof. [Athina Markopoulou](https://athinagroup.eng.uci.edu/athina/). I received my B.E. degree in Electrical Engineering from Northeastern University (China) in 2019, my M.Sc. degree in Electrical Engineering from University of Southern California in 2021. I was a visiting student at City University of Hong Kong in 2018, supervised by Prof. [Linqi Song](https://sites.google.com/site/aisquaredlab/about-us/linqi?authuser=0).

My research interests are in the areas of Federated Learning, Privacy-preserving machine learning, IoT and data privacy. 

Education
======

* **University of California, Irvine, 09/2021 - Present**
  * Degree: PhD
  * Major: Electrical Engineering
  * GPA: 4.0/4.0

* **University of Southern California, 08/2019 - 05/2021**
  * Degree: Master
  * Major: Electrical Engineering
  * GPA: 3.71/4.0

* **Northeastern University (China), 09/2015 - 06/2019**
  * Degree: Bachelor
  * Major: Electronic Information Engineering
  * GPA: 93/100

<!-- Research Experience
======

* PriPrune: Quantifying and Preserving Privacy in Pruned FL, 2022.11 – 2023.8.
  * Advisor: Prof. Athina Markopoulou (University of California Irvine).
  * Performed the first investigation of privacy guarantees for model pruning in FL. We also derived information-
theoretic upper bounds on the amount of information leaked by pruned FL models.
  * Introduced PriPrune – a privacy-aware algorithm for local model pruning, which uses a personalized per-
client defense mask and adapts the defense pruning rate so as to jointly optimize privacy and model perfor-
mance.

* Information Leakage In Personalized Federated Learning, 2022.4 – 2022.6.
  * Advisor: Prof. Athina Markopoulou (University of California Irvine).
  * Launched the gradient leakage attack (DLG attack) in personalized federated learning and articulated how personalized FL can influence the DLG attack with regard to different level of personalization. We showed that with low-level personalization, the DLG attack could easily reconstruct clients’ training data but with high-level personalization, the overall performance of DLG attack deteriorated a lot.
  * Proposed the PerFed-LDP, the per-example level differential privacy for personalized federated learning. We analyzed the privacy-utility tradeoff of PerFed-LDP and demonstrated the results of DLG attack in differentially private personalized FL.

* Privacy by Projection: Federated Population Density Estimation by Projecting on Random Features, 2021.12 – 2022.07.
  * Advisor: Prof. Athina Markopoulou (University of California Irvine).
  * Proposed a federated KDE framework for estimating the user population density,which not only kept users’ data local, but also protected against a malicious server that tries to infer users’ locations.
  * Our proposed federated Random Fourier feature (RFF) KDE leveraged a random feature representation of the KDE solution, in which each user’s information was irreversibly projected onto a small number of spatially delocalized basis functions.

* Location Leakage in Federated Signal Maps, 2021.11 – 2022.04.
  * Advisor: Prof. Athina Markopoulou (University of California Irvine).
  * launched the gradients leakage attack (DLG attack) on signal map prediction tasks and successfully recon- structed the average location of users’ private spatiotemporal dataset during the federated training process.
  * Proposed a defense approach that selects local batches so that the inferred location is far from the true average location, thus misleading the DLG attacker. Explored the tradeoff between utility in federated
signal map task and privacy in protecting clients’ data.

* SaferQ: Obfuscating Search Queries via Generative Adversarial Privacy, 2020.03 – 2020.05.
  * Advisor: Prof. Keith Chugg (University of Southern California).
  * Our proposed SaferQ extended the existing Generative Adversarial Privacy framework for sequence gen- eration problems. Deployed between browser and query log databases. Query logs will be obfuscated by SaferQ based on our desired privacy and utility tradeoff ratio.

* Secure Federated XGBoost Framework, 2018.09 – 2019.08.
  * Advisor: Prof. Linqi Song (City University of Hong Kong).
  * Our proposed secure federated XGBoost algorithm incorporated data aggregation and sparse federated up-
date processes to balance the tradeoff between privacy and learning performance.
  * Based on the characteristics of split finding in XGBoost, we introduced the anonymous virtual data cluster
in the data aggregation process and thus hided a specific user’s gradients under the anonymous cluster.


Work Experience
======

* 07/2022 - 09/2022: Engineering Intern
  * Syntiant Corp.
  * Research on keyword spotting with student-teacher framework.
  
* 06/2020 - 01/2021: Data Science Internship
  * Ericsson Inc.
  * Research on secure federated learning with XGBoost. -->

<!-- Preprints
====== -->

<!-- Publications
============

Chu, Tianyue\*, **Yang, Mengwei**\*, and Laoutaris, Nikolaos, and Markopoulou, Athina. “[PriPrune: Quantifying and Preserving Privacy in Pruned Federated Learning](https://arxiv.org/pdf/2310.19958.pdf)”, arXiv preprint arXiv:2310.19958 (2023), under review.

Bakopoulou, Evita\*, **Yang, Mengwei**\*, and Zhang, Jiang and Psounis, Konstantinos and Markopoulou, Athina, "[Location leakage in federated signal maps](https://arxiv.org/pdf/2112.03452.pdf).", accepted in IEEE Transactions on Mobile Computing, Oct. 2023

Zong, Zixiao and **Yang, Mengwei** and Ley, Justin and Butts, Carter T and Markopoulou, Athina, "[Privacy by projection: Federated population density estimation by projecting on random features](https://petsymposium.org/popets/2023/popets-2023-0019.pdf).", in Proceedings of Privacy Enhancing Technologies (PoPETs), 2023(1), Lausanne, Switzerland, July 2023.

**Yang, Mengwei** and Song, Linqi and Xu, Jie and Li, Congduan and Tan, Guozhen, "[The Tradeoff Between Privacy and Accuracy in Anomaly Detection Using Federated XGBoost](https://arxiv.org/pdf/1907.07157.pdf)", accepted and to appear in IJCAI Workshop: 1st International Workshop on Federated Machine Learning for User Privacy and Data Confidentiality (IJCAI-FL 2019).

(* means equal contributions) -->

<!-- Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful. -->
